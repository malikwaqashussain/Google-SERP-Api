{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# List of keywords you want to search for. For large scale, replace this with a CSV file and keep kw data under a column.\n",
        "keywords = [\"google analytics 4 bigquery\", \"gsc bq schema\", \"how does the bigquery export work\"]"
      ],
      "metadata": {
        "id": "_LqFU5qDFOfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# API endpoint\n",
        "url = \"https://api.dataforseo.com/v3/serp/google/organic/live/advanced\"\n",
        "# Your authentication credentials\n",
        "headers = {\n",
        "    'Authorization': 'Basic write_key_here', # This is where you add your key, leave Basic as it is\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# Create a results directory if it doesn't exist\n",
        "results_dir = \"serp_results\"\n",
        "if not os.path.exists(results_dir):\n",
        "    os.makedirs(results_dir)\n",
        "\n",
        "# Get timestamp for the run\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Process each keyword\n",
        "for keyword in keywords:\n",
        "    # Create the payload for the current keyword\n",
        "    payload = json.dumps([{\n",
        "        \"keyword\": keyword,\n",
        "        \"location_code\": 2840,\n",
        "        \"language_code\": \"en\",\n",
        "        \"device\": \"mobile\",\n",
        "        \"os\": \"ios\",\n",
        "        \"depth\": 10,\n",
        "        \"calculate_rectangles\": True,\n",
        "        \"group_organic_results\": True,\n",
        "        \"load_async_ai_overview\":True\n",
        "    }])\n",
        "\n",
        "    # Send the request\n",
        "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "\n",
        "    # Print the response status for the current keyword\n",
        "    print(f\"Results for keyword: {keyword}\")\n",
        "    print(f\"Status code: {response.status_code}\")\n",
        "\n",
        "    # Save the response to a file\n",
        "    # Create a safe filename from the keyword\n",
        "    safe_keyword = keyword.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
        "    filename = f\"{results_dir}/{timestamp}_{safe_keyword}.json\"\n",
        "\n",
        "    with open(filename, \"w\") as file:\n",
        "        # If the response is valid JSON, pretty print it to the file\n",
        "        try:\n",
        "            json_response = response.json()\n",
        "            json.dump(json_response, file, indent=4)\n",
        "            print(f\"Results saved to {filename}\")\n",
        "        except json.JSONDecodeError:\n",
        "            # If not valid JSON, save the raw text\n",
        "            file.write(response.text)\n",
        "            print(f\"Non-JSON response saved to {filename}\")\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Add a short delay to avoid hitting rate limits\n",
        "    time.sleep(1)\n",
        "\n",
        "print(f\"All results have been saved to the '{results_dir}' directory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjEcp6TyE3fZ",
        "outputId": "40d62bf4-b8ef-41d1-c379-a28fbee703da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for keyword: google analytics 4 bigquery\n",
            "Status code: 401\n",
            "Results saved to serp_results/20250526_033729_google_analytics_4_bigquery.json\n",
            "--------------------------------------------------\n",
            "Results for keyword: gsc bq schema\n",
            "Status code: 401\n",
            "Results saved to serp_results/20250526_033729_gsc_bq_schema.json\n",
            "--------------------------------------------------\n",
            "Results for keyword: how does the bigquery export work\n",
            "Status code: 401\n",
            "Results saved to serp_results/20250526_033729_how_does_the_bigquery_export_work.json\n",
            "--------------------------------------------------\n",
            "All results have been saved to the 'serp_results' directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we combine all the files into one:"
      ],
      "metadata": {
        "id": "SxFxw4mzFRLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas import json_normalize\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Directory where the JSON files are saved\n",
        "results_dir = \"serp_results\"\n",
        "\n",
        "# Create an empty list to store all results\n",
        "all_results = []\n",
        "\n",
        "# Get all JSON files in the results directory\n",
        "json_files = glob.glob(f\"{results_dir}/*.json\")\n",
        "\n",
        "# Process each JSON file\n",
        "for json_file in json_files:\n",
        "    print(f\"Processing file: {json_file}\")\n",
        "\n",
        "    # Extract the keyword from the filename\n",
        "    filename = os.path.basename(json_file)\n",
        "    # Assuming filename format: timestamp_keyword.json from the first script\n",
        "    # We need to remove the timestamp part (YYYYMMDD_HHMMSS_) and the file extension\n",
        "    parts = filename.split('_')\n",
        "    # Remove timestamp parts (first two elements) and file extension\n",
        "    if len(parts) >= 3:  # Make sure we have at least: date_time_keyword.json\n",
        "        keyword_parts = parts[2:]  # Skip the date and time parts\n",
        "        keyword = ' '.join([part.replace('.json', '') for part in keyword_parts])\n",
        "    else:\n",
        "        # Fallback in case the filename format is different\n",
        "        print(f\"Warning: Unexpected filename format: {filename}\")\n",
        "        keyword = filename.replace('.json', '')\n",
        "\n",
        "    try:\n",
        "        # Read the JSON file\n",
        "        with open(json_file, 'r') as file:\n",
        "            response_data = json.load(file)\n",
        "\n",
        "        # Check if the request was successful\n",
        "        if isinstance(response_data, list):\n",
        "            # Handle the case when response is a list\n",
        "            for task_data in response_data:\n",
        "                if task_data.get(\"status_code\") == 20000:\n",
        "                    # Extract the organic search results\n",
        "                    try:\n",
        "                        # Navigate through the JSON structure to get to the organic results\n",
        "                        result_items = task_data.get(\"result\", [])\n",
        "                        for result in result_items:\n",
        "                            organic_results = result.get(\"items\", [])\n",
        "\n",
        "                            # Add the current keyword to each result for reference\n",
        "                            for organic_result in organic_results:\n",
        "                                organic_result[\"keyword\"] = keyword\n",
        "                                all_results.append(organic_result)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing results in {json_file}: {str(e)}\")\n",
        "                else:\n",
        "                    print(f\"Error in {json_file}: {task_data.get('status_message')}\")\n",
        "        elif response_data.get(\"status_code\") == 20000:\n",
        "            # Handle the case when response is a dictionary\n",
        "            try:\n",
        "                # Navigate through the JSON structure to get to the organic results\n",
        "                tasks = response_data.get(\"tasks\", [])\n",
        "                for task in tasks:\n",
        "                    task_result = task.get(\"result\", [])\n",
        "                    for result in task_result:\n",
        "                        organic_results = result.get(\"items\", [])\n",
        "\n",
        "                        # Add the current keyword to each result for reference\n",
        "                        for organic_result in organic_results:\n",
        "                            organic_result[\"keyword\"] = keyword\n",
        "                            all_results.append(organic_result)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing results in {json_file}: {str(e)}\")\n",
        "        else:\n",
        "            print(f\"Error in {json_file}: {response_data.get('status_message')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading or parsing {json_file}: {str(e)}\")\n",
        "\n",
        "# Convert all results to a DataFrame\n",
        "if all_results:\n",
        "    print(f\"Total results collected: {len(all_results)}\")\n",
        "\n",
        "    # Use json_normalize to flatten nested JSON\n",
        "    df = json_normalize(all_results)\n",
        "\n",
        "    # Display the first few rows\n",
        "    print(\"Preview of the first few rows:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Save to CSV\n",
        "    output_file = 'dataforseo_combined_results.csv'\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"All results saved to '{output_file}'\")\n",
        "else:\n",
        "    print(\"No results found in any file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DhA9g5oFQwX",
        "outputId": "67aaa920-3521-4775-d288-40ab9bd8b8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: serp_results/20250526_033729_gsc_bq_schema.json\n",
            "Error in serp_results/20250526_033729_gsc_bq_schema.json: You are not Authorized to Access this Resource. Your Login Information Here: https://app.dataforseo.com/login .\n",
            "Processing file: serp_results/20250526_033729_how_does_the_bigquery_export_work.json\n",
            "Error in serp_results/20250526_033729_how_does_the_bigquery_export_work.json: You are not Authorized to Access this Resource. Your Login Information Here: https://app.dataforseo.com/login .\n",
            "Processing file: serp_results/20250526_033729_google_analytics_4_bigquery.json\n",
            "Error in serp_results/20250526_033729_google_analytics_4_bigquery.json: You are not Authorized to Access this Resource. Your Login Information Here: https://app.dataforseo.com/login .\n",
            "No results found in any file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing SERP Types"
      ],
      "metadata": {
        "id": "oZ-eGRjgA7hN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Check if 'type' column exists\n",
        "if 'type' not in df.columns:\n",
        "    print(\"Column 'type' not found. Available columns are:\", df.columns.tolist())\n",
        "else:\n",
        "    # Count the frequency of each type\n",
        "    type_counts = df['type'].value_counts().reset_index()\n",
        "    type_counts.columns = ['Type', 'Count']\n",
        "\n",
        "    # Calculate percentages\n",
        "    type_counts['Percentage'] = (type_counts['Count'] / type_counts['Count'].sum() * 100).round(2)\n",
        "\n",
        "    # Create a horizontal bar chart with Plotly\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Color scale for gradient effect\n",
        "    colors = px.colors.sequential.Plasma\n",
        "\n",
        "    # Add the horizontal bar chart with custom styling\n",
        "    fig.add_trace(go.Bar(\n",
        "        y=type_counts['Type'],\n",
        "        x=type_counts['Count'],\n",
        "        text=type_counts['Count'],\n",
        "        textposition='outside',\n",
        "        textfont=dict(\n",
        "            family='Trebuchet MS, sans-serif',\n",
        "            size=14,\n",
        "            color='rgba(50, 50, 50, 0.8)'\n",
        "        ),\n",
        "        orientation='h',\n",
        "        marker=dict(\n",
        "            color=type_counts['Count'],\n",
        "            colorscale=colors,\n",
        "            line=dict(color='rgba(0,0,0,0.3)', width=1.5)\n",
        "        ),\n",
        "        hovertemplate='<b>%{y}</b><br>Count: %{x}<br>Percentage: %{customdata:.2f}%<extra></extra>',\n",
        "        customdata=type_counts['Percentage']\n",
        "    ))\n",
        "\n",
        "    # Customize layout\n",
        "    fig.update_layout(\n",
        "        title={\n",
        "            'text': 'Distribution of Result Types',\n",
        "            'y':0.97,\n",
        "            'x':0.5,\n",
        "            'xanchor': 'center',\n",
        "            'yanchor': 'top',\n",
        "            'font': dict(\n",
        "                family='Raleway, sans-serif',\n",
        "                size=28,\n",
        "                color='rgba(0,0,0,0.85)'\n",
        "            )\n",
        "        },\n",
        "        yaxis_title=\"\",\n",
        "        xaxis_title=\"\",\n",
        "        template=\"plotly_white\",\n",
        "        height=max(500, len(type_counts) * 45),  # Dynamic height based on number of categories\n",
        "        width=950,\n",
        "        yaxis={\n",
        "            'categoryorder':'total ascending',\n",
        "            'tickfont': dict(\n",
        "                family='Roboto, sans-serif',\n",
        "                size=16,\n",
        "                color='rgba(0,0,0,0.75)'\n",
        "            ),\n",
        "            'gridwidth': 0.1,\n",
        "            'gridcolor': 'rgba(0,0,0,0.05)'\n",
        "        },\n",
        "        xaxis={\n",
        "            'showgrid': True,\n",
        "            'gridwidth': 0.1,\n",
        "            'gridcolor': 'rgba(0,0,0,0.05)',\n",
        "            'zeroline': False,\n",
        "            'tickfont': dict(\n",
        "                family='Roboto, sans-serif',\n",
        "                size=14,\n",
        "                color='rgba(0,0,0,0.6)'\n",
        "            )\n",
        "        },\n",
        "        hoverlabel=dict(\n",
        "            bgcolor=\"white\",\n",
        "            font_size=16,\n",
        "            font_family=\"Montserrat, sans-serif\",\n",
        "            bordercolor=\"rgba(0,0,0,0.2)\"\n",
        "        ),\n",
        "        margin=dict(l=20, r=60, t=80, b=40),\n",
        "        bargap=0.25,  # Gap between bars\n",
        "        plot_bgcolor='rgba(250,250,250,0.95)'  # Slight off-white background\n",
        "    )\n",
        "\n",
        "    # Add subtle grid lines\n",
        "    fig.update_yaxes(showgrid=False)\n",
        "\n",
        "    # Display the interactive chart\n",
        "    fig.show()\n",
        "\n",
        "    # Print the distribution summary as a styled table\n",
        "    fig_table = go.Figure(data=[go.Table(\n",
        "        header=dict(\n",
        "            values=['Type', 'Count', 'Percentage (%)'],\n",
        "            fill_color='rgba(82, 45, 128, 0.8)',  # Deep purple header\n",
        "            align='center',\n",
        "            font=dict(\n",
        "                family='Raleway, sans-serif',\n",
        "                color='white',\n",
        "                size=15\n",
        "            )\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values=[type_counts['Type'], type_counts['Count'], type_counts['Percentage']],\n",
        "            fill_color=[['rgba(237, 231, 246, 0.5)', 'rgba(248, 245, 255, 0.5)'] * (len(type_counts)//2 + 1)],\n",
        "            align='center',\n",
        "            font=dict(\n",
        "                family='Roboto, sans-serif',\n",
        "                size=14,\n",
        "                color=['rgba(0,0,0,0.7)']\n",
        "            ),\n",
        "            height=30\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    fig_table.update_layout(\n",
        "        title={\n",
        "            'text': \"Distribution Summary\",\n",
        "            'font': dict(\n",
        "                family='Raleway, sans-serif',\n",
        "                size=22,\n",
        "                color='rgba(0,0,0,0.85)'\n",
        "            )\n",
        "        },\n",
        "        height=max(350, len(type_counts) * 30 + 100),\n",
        "        margin=dict(l=10, r=10, t=50, b=15)\n",
        "    )\n",
        "\n",
        "    fig_table.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "oedr2r8fFcm9",
        "outputId": "fd479048-fe8b-4d88-fb72-cb0da797decd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-dce42571b4f1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Check if 'type' column exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m'type'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column 'type' not found. Available columns are:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(\"/content/dataforseo_combined_results.csv\").head(50)"
      ],
      "metadata": {
        "id": "xrn8GvRAGOwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pixel Ranking"
      ],
      "metadata": {
        "id": "nLguPijlGmcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define above fold threshold (in pixels)\n",
        "above_fold_threshold = 400\n",
        "\n",
        "# Create a new column indicating whether the element is above the fold\n",
        "df['is_above_fold'] = df['rectangle.y'] < above_fold_threshold\n",
        "\n",
        "# Count how many elements are above/below the fold\n",
        "above_fold_count = df['is_above_fold'].sum()\n",
        "below_fold_count = len(df) - above_fold_count\n",
        "\n",
        "print(f\"Total elements: {len(df)}\")\n",
        "print(f\"Elements above the fold: {above_fold_count} ({above_fold_count/len(df)*100:.2f}%)\")\n",
        "print(f\"Elements below the fold: {below_fold_count} ({below_fold_count/len(df)*100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EkkHEZYGpry",
        "outputId": "889505b5-7ed8-466a-e03b-af061b3cc20e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total elements: 40\n",
            "Elements above the fold: 5 (12.50%)\n",
            "Elements below the fold: 35 (87.50%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing the same but for each keyword:"
      ],
      "metadata": {
        "id": "otaaKPYRBAv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define above fold threshold (in pixels)\n",
        "above_fold_threshold = 400\n",
        "\n",
        "# Create a new column indicating whether the element is above the fold\n",
        "df['is_above_fold'] = df['rectangle.y'] < above_fold_threshold\n",
        "\n",
        "# Group by keyword and calculate counts for each\n",
        "keyword_counts = df.groupby('keyword').apply(\n",
        "    lambda group: {\n",
        "        'total': len(group),\n",
        "        'above_fold': group['is_above_fold'].sum(),\n",
        "        'below_fold': len(group) - group['is_above_fold'].sum()\n",
        "    },         include_groups=False\n",
        ").to_dict()\n",
        "\n",
        "# Print results for each keyword\n",
        "for keyword, counts in keyword_counts.items():\n",
        "    total = counts['total']\n",
        "    above = counts['above_fold']\n",
        "    below = counts['below_fold']\n",
        "\n",
        "    print(f\"\\nKeyword: {keyword}\")\n",
        "    print(f\"Total elements: {total}\")\n",
        "    print(f\"Elements above the fold: {above} ({above/total*100:.2f}%)\")\n",
        "    print(f\"Elements below the fold: {below} ({below/total*100:.2f}%)\")\n",
        "\n",
        "# Overall totals (optional)\n",
        "print(\"\\nOVERALL TOTALS:\")\n",
        "print(f\"Total elements: {len(df)}\")\n",
        "print(f\"Elements above the fold: {df['is_above_fold'].sum()} ({df['is_above_fold'].sum()/len(df)*100:.2f}%)\")\n",
        "print(f\"Elements below the fold: {len(df) - df['is_above_fold'].sum()} ({(len(df) - df['is_above_fold'].sum())/len(df)*100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KICVZjSOGsmw",
        "outputId": "13bd8df6-4ff1-471a-a09c-282ad3657188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Keyword: google analytics 4 bigquery\n",
            "Total elements: 13\n",
            "Elements above the fold: 2 (15.38%)\n",
            "Elements below the fold: 11 (84.62%)\n",
            "\n",
            "Keyword: gsc bq schema\n",
            "Total elements: 13\n",
            "Elements above the fold: 2 (15.38%)\n",
            "Elements below the fold: 11 (84.62%)\n",
            "\n",
            "Keyword: how does the bigquery export work\n",
            "Total elements: 14\n",
            "Elements above the fold: 1 (7.14%)\n",
            "Elements below the fold: 13 (92.86%)\n",
            "\n",
            "OVERALL TOTALS:\n",
            "Total elements: 40\n",
            "Elements above the fold: 5 (12.50%)\n",
            "Elements below the fold: 35 (87.50%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(50)"
      ],
      "metadata": {
        "id": "3l2-voXjG3Ap"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}